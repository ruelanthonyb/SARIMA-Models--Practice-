{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88de941",
   "metadata": {},
   "source": [
    "## SARIMA Models (Practice)\n",
    "For this assignment, you will be predicting energy consumption for the next 24 months. You will ultimately be comparing a seasonal and nonseasonal model.\n",
    "\n",
    "You can access the data here. (Original Source)\n",
    "* We will look at the \"Consumption\" column for our time series.\n",
    "* Convert the Date column to datetime and make it the index.\n",
    "* Resample the data to a monthly frequency calculated with the mean.\n",
    "* Check for and address missing values.\n",
    "* Plot the time series.\n",
    "\n",
    "ARIMA\n",
    "* Use ndiffs to determine if nonseasonal differencing is required\n",
    "* Plot ACF and PACF to estimate initial orders\n",
    "* Train test split the data using a test_size equal to the length of the final forecast (24 months) and visualize the result.\n",
    "* Run an ARIMA model with the orders determined based on your EDA.\n",
    "* Obtain the model summary, plot diagnostics, plot the forecasts with confidence intervals, and obtain regression metrics for the ARIMA model.\n",
    "\n",
    "SARIMA\n",
    "* Use nsdiffs to determine if seasonal differencing is required\n",
    "* Apply seasonal decomposition to the data\n",
    "* Plot the seasonal component to determine m.\n",
    "* Determine the size and relative size of m.\n",
    "* Examine the seasonal lags of the ACF/PACF to determine seasonal orders\n",
    "* Run a SARIMA model with the orders determined based on your EDA.\n",
    "* Obtain the model summary, plot diagnostics, plot the forecasts with confidence intervals, and obtain regression metrics for the ARIMA model.\n",
    "* Notice how adding a seasonal component improves this model\n",
    "\n",
    "Submit below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b982b0e5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "# set random seed\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "plt.rcParams['figure.figsize']=(12,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585eccb",
   "metadata": {},
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1784666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781126e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea25a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d864f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "\n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb52c39",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c838197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb2530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34c491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab6868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448309ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
